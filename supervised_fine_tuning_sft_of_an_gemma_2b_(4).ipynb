{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWnbdCyHBpA-"
      },
      "source": [
        "# Supervised fine tuning Gemma on chat Task\n",
        "Recall that creating a ChatGPT at home involves 3 steps:\n",
        "\n",
        "1. pre-training a large language model (LLM) to predict the next token on internet-scale data, on clusters of thousands of GPUs. One calls the result a \"base model\"\n",
        "2. supervised fine-tuning (SFT) to turn the base model into a useful assistant\n",
        "3. human preference fine-tuning which increases the assistant's friendliness, helpfulness and safety.\n",
        "\n",
        "in this Notebook I will do the second step. This involves supervised fine-tuning (SFT for short), also called instruction tuning.\n",
        "\n",
        "Supervised fine-tuning takes in a \"base model\" from step 1, i.e. a model that has been pre-trained on predicting the next token on internet text, and turns it into a \"chatbot\"/\"assistant\". This is done by fine-tuning the model on human instruction data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPgFIP2JBpA_"
      },
      "source": [
        "## Set-up environment\n",
        "\n",
        "* BitsandBytes and PEFT for fine-tuning the model on consumer hardware, leveraging\n",
        "* TRL, a library which includes useful Trainer classes for LLM fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T14:57:00.124999Z",
          "iopub.status.busy": "2024-07-15T14:57:00.124585Z",
          "iopub.status.idle": "2024-07-15T14:57:16.717846Z",
          "shell.execute_reply": "2024-07-15T14:57:16.716485Z",
          "shell.execute_reply.started": "2024-07-15T14:57:00.124965Z"
        },
        "id": "ZJrUUw-TBpBA",
        "outputId": "c3da188a-c78e-4e67-f70d-333b4cbefbeb",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q bitsandbytes trl peft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi5nA64KBpBA"
      },
      "source": [
        "We also install Flash\n",
        "\n",
        "Attention, which speeds up the attention computations of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T14:57:22.696421Z",
          "iopub.status.busy": "2024-07-15T14:57:22.695510Z",
          "iopub.status.idle": "2024-07-15T14:57:53.506113Z",
          "shell.execute_reply": "2024-07-15T14:57:53.505204Z",
          "shell.execute_reply.started": "2024-07-15T14:57:22.696382Z"
        },
        "id": "NrSK8WiUBpBA",
        "outputId": "ef50555f-acab-4788-8678-32358d3a123e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.6.1.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.3.0+cu121)\n",
            "Collecting einops (from flash-attn)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.6.1-cp310-cp310-linux_x86_64.whl size=198447665 sha256=808523ff263d2fc1d3801147ad90d89dbfca67623a110c26592aef2064ea7b65\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/6a/38/f0faa036b4ac73a73247386f1ab1bb4cb4f6e72e6861a779f1\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: einops, flash-attn\n",
            "Successfully installed einops-0.8.0 flash-attn-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbZtjED_BpBB"
      },
      "source": [
        "## Load dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-15T14:57:53.508937Z",
          "iopub.status.busy": "2024-07-15T14:57:53.508548Z",
          "iopub.status.idle": "2024-07-15T14:58:28.601192Z",
          "shell.execute_reply": "2024-07-15T14:58:28.600190Z",
          "shell.execute_reply.started": "2024-07-15T14:57:53.508904Z"
        },
        "id": "THQZU-lTBpBB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# based on config\n",
        "raw_datasets = load_dataset(\"HuggingFaceH4/ultrachat_200k\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T14:58:28.602882Z",
          "iopub.status.busy": "2024-07-15T14:58:28.602419Z",
          "iopub.status.idle": "2024-07-15T14:58:28.609972Z",
          "shell.execute_reply": "2024-07-15T14:58:28.608781Z",
          "shell.execute_reply.started": "2024-07-15T14:58:28.602855Z"
        },
        "id": "t552_meRBpBB",
        "outputId": "66a10182-a0c6-45fe-8bce-d67bcf9dd449",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages'],\n",
              "        num_rows: 207865\n",
              "    })\n",
              "    test_sft: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages'],\n",
              "        num_rows: 23110\n",
              "    })\n",
              "    train_gen: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages'],\n",
              "        num_rows: 256032\n",
              "    })\n",
              "    test_gen: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages'],\n",
              "        num_rows: 28304\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T14:58:28.613030Z",
          "iopub.status.busy": "2024-07-15T14:58:28.612631Z",
          "iopub.status.idle": "2024-07-15T14:58:30.242817Z",
          "shell.execute_reply": "2024-07-15T14:58:30.241583Z",
          "shell.execute_reply.started": "2024-07-15T14:58:28.612991Z"
        },
        "id": "e7xYAprqBpBC",
        "outputId": "c2a1662f-aac2-4396-e440-65cc6bcc9ae7",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': 'This story begins with an end. In March 1991, after a three-month stay at Dr Bharat Vatwani’s Shraddha Nursing Home in Mumbai, Gangadhar Vinode, then 17, returned to his village near Wakad, in Pune. Earlier that year, the schizophrenic was found lying by a drain in Mumbai and had been picked up by staffers of Missionaries of Charity.\\nWhen Dr Vatwani, who used to help the Missionaries of Charity with their work, saw him at the centre, he decided to take him under his wing. “He was not in good shape; I told them I wanted to try and cure him,” Dr Vatwani says. Towards the end of his stay at the nursing home, Vinode provided Dr Vatwani his address in Wakad, and the doctor rode down to Pune to inform his parents about their son. The next day, Vinode’s parents and grandfather arrived at the nursing home with tons of sweets, performed an aarti for Dr Vatwani, and left with their son.\\nVinode, who has a shy smile and a childlike excitement, has just completed his third housing project in Pune. After being successfully treated by Dr Vatwani, he resolutely got back to work on his family’s farm, set up a brick kiln and a service centre for cars before eventually moving into construction about six years ago. He says he has no recollection of what happened to him that winter 27 years ago. All the 46-year-old wrestling buff remembers is going to Kolhapur to spend some time at an akhara, and preparing to return after a month there.\\n“I had boarded a bus bound for Pune, but somehow I found myself in doctor sir’s nursing home,” says Vinode. “Since then, it’s been God, my parents and Dr Vatwani.” His colleague, Lawrence Fernandes, and nephew Vishal Wakadkar, say they still find it tough to believe that “Ganga bhau”, who co-runs Vinode Constructions, once roamed the streets oblivious to everything.\\nBut Dr Vatwani has been battling the odds since he was a child. After his father, a high ranking government official, died an untimely death, he and his brothers, who were then still in school, sold photos of movie stars to their classmates, and books and gramophone records to the residents of Bandra, where they lived, to make ends meet. He would ring the doorbell, say he was hard up, and offer his wares.\\nHe has been on the other side as well. About a decade after he started his nursing home along with wife Smita, he slipped into severe depression when his desire for a bigger set-up met with resistance from locals and was mired in a court case. The courts eventually ruled in his favour, but it was a meeting with the late social activist Baba Amte in the 1990s that changed his life.\\nDr Vatwani was driving down to Hemalkasa, in Gadchiroli, where the Amtes worked among the Madia Gond tribe, when he spotted a mentally ill man, his hands and feet bound in chains, walking by the road. He coaxed him to come with him in the car.\\n“That was how I first met Baba Amte and Prakash (Amte’s son). I landed up there with an unwashed, bedraggled man in chains, and told them we needed to get those chains off.” Prakash Amte, says Dr Vatwani, took a hammer and started striking the links in the chains. The next morning, Dr Vatwani found Baba Amte crying.\\n“He said he empathised with the plight of wandering mentally ill people, but had never been able to do anything for them. He said while I was doing good work, it was not enough. He said I was ‘chosen’, and that fired me up,” says Dr Vatwani, who set up the 120-bed Shraddha Rehabilitation Foundation, in Karjat, in 2006, and has since then helped people from across the country reunite with themselves and their families.\\nHe is also aware of his advancing age, and hopes that the Magsaysay award will help him find people whom he can hand the baton over to. “I’m pushing 60, how long can I keep up with this? If it can get more NGOs, bureaucrats and society to talk about the mentally ill destitute, that would be good, especially in a country where religion and black magic are still supposed to cure mental illness. If it were not for his family’s support, Vinode would have taken much longer to be the man he is today.” Baba Amte, says Dr Vatwani, ignited the spark in him, and now he is looking for others with the “same spark”.\\nToday, many of his former patients, including Vinode, regularly donate funds to NGOs and organisations involved in mental health care, and each time he spots a mentally-ill destitute, Vinode makes it a point to bring him home and bathe him, or if he is violent, call up local organisations to take care of the person. It might be the glimmer of a beginning, but it is a beginning all the same. Based on the passage above, Could you paraphrase the story of Gangadhar Vinode and how Dr Vatwani helped him overcome his schizophrenia and become successful in the construction industry?',\n",
              " 'prompt_id': '5ee2fbb48ef35593b81444d7aec405bb4f152abbe80f7b90534e871549ff88ac',\n",
              " 'messages': [{'content': 'This story begins with an end. In March 1991, after a three-month stay at Dr Bharat Vatwani’s Shraddha Nursing Home in Mumbai, Gangadhar Vinode, then 17, returned to his village near Wakad, in Pune. Earlier that year, the schizophrenic was found lying by a drain in Mumbai and had been picked up by staffers of Missionaries of Charity.\\nWhen Dr Vatwani, who used to help the Missionaries of Charity with their work, saw him at the centre, he decided to take him under his wing. “He was not in good shape; I told them I wanted to try and cure him,” Dr Vatwani says. Towards the end of his stay at the nursing home, Vinode provided Dr Vatwani his address in Wakad, and the doctor rode down to Pune to inform his parents about their son. The next day, Vinode’s parents and grandfather arrived at the nursing home with tons of sweets, performed an aarti for Dr Vatwani, and left with their son.\\nVinode, who has a shy smile and a childlike excitement, has just completed his third housing project in Pune. After being successfully treated by Dr Vatwani, he resolutely got back to work on his family’s farm, set up a brick kiln and a service centre for cars before eventually moving into construction about six years ago. He says he has no recollection of what happened to him that winter 27 years ago. All the 46-year-old wrestling buff remembers is going to Kolhapur to spend some time at an akhara, and preparing to return after a month there.\\n“I had boarded a bus bound for Pune, but somehow I found myself in doctor sir’s nursing home,” says Vinode. “Since then, it’s been God, my parents and Dr Vatwani.” His colleague, Lawrence Fernandes, and nephew Vishal Wakadkar, say they still find it tough to believe that “Ganga bhau”, who co-runs Vinode Constructions, once roamed the streets oblivious to everything.\\nBut Dr Vatwani has been battling the odds since he was a child. After his father, a high ranking government official, died an untimely death, he and his brothers, who were then still in school, sold photos of movie stars to their classmates, and books and gramophone records to the residents of Bandra, where they lived, to make ends meet. He would ring the doorbell, say he was hard up, and offer his wares.\\nHe has been on the other side as well. About a decade after he started his nursing home along with wife Smita, he slipped into severe depression when his desire for a bigger set-up met with resistance from locals and was mired in a court case. The courts eventually ruled in his favour, but it was a meeting with the late social activist Baba Amte in the 1990s that changed his life.\\nDr Vatwani was driving down to Hemalkasa, in Gadchiroli, where the Amtes worked among the Madia Gond tribe, when he spotted a mentally ill man, his hands and feet bound in chains, walking by the road. He coaxed him to come with him in the car.\\n“That was how I first met Baba Amte and Prakash (Amte’s son). I landed up there with an unwashed, bedraggled man in chains, and told them we needed to get those chains off.” Prakash Amte, says Dr Vatwani, took a hammer and started striking the links in the chains. The next morning, Dr Vatwani found Baba Amte crying.\\n“He said he empathised with the plight of wandering mentally ill people, but had never been able to do anything for them. He said while I was doing good work, it was not enough. He said I was ‘chosen’, and that fired me up,” says Dr Vatwani, who set up the 120-bed Shraddha Rehabilitation Foundation, in Karjat, in 2006, and has since then helped people from across the country reunite with themselves and their families.\\nHe is also aware of his advancing age, and hopes that the Magsaysay award will help him find people whom he can hand the baton over to. “I’m pushing 60, how long can I keep up with this? If it can get more NGOs, bureaucrats and society to talk about the mentally ill destitute, that would be good, especially in a country where religion and black magic are still supposed to cure mental illness. If it were not for his family’s support, Vinode would have taken much longer to be the man he is today.” Baba Amte, says Dr Vatwani, ignited the spark in him, and now he is looking for others with the “same spark”.\\nToday, many of his former patients, including Vinode, regularly donate funds to NGOs and organisations involved in mental health care, and each time he spots a mentally-ill destitute, Vinode makes it a point to bring him home and bathe him, or if he is violent, call up local organisations to take care of the person. It might be the glimmer of a beginning, but it is a beginning all the same. Based on the passage above, Could you paraphrase the story of Gangadhar Vinode and how Dr Vatwani helped him overcome his schizophrenia and become successful in the construction industry?',\n",
              "   'role': 'user'},\n",
              "  {'content': \"Gangadhar Vinode, a schizophrenic, was found by the Missionaries of Charity in Mumbai and was taken to Dr Bharat Vatwani’s Shraddha Nursing Home. Dr Vatwani decided to help him and eventually contacted Vinode's parents in Pune. After three months at the nursing home, Vinode returned to his village and resumed working on his family's farm. He later set up a brick kiln, a service center for cars, and eventually became involved in the construction industry. Despite having no recollection of what happened to him during his illness, Vinode credits his recovery to God, his parents, and Dr Vatwani. Dr Vatwani, who grew up in poverty and faced obstacles when starting his own nursing home, was inspired by a chance encounter with Baba Amte and later established the Shraddha Rehabilitation Foundation to help the mentally ill destitute. He hopes that the recent recognition from the Magsaysay award will encourage others to join the cause. Many of his former patients, including Vinode, donate funds to mental health care organizations, and Vinode helps other mentally ill destitute he encounters.\",\n",
              "   'role': 'assistant'},\n",
              "  {'content': 'Can you provide more information about the Shraddha Rehabilitation Foundation that Dr Vatwani established to help the mentally ill destitute?',\n",
              "   'role': 'user'}]}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets['test_gen'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T14:58:30.244505Z",
          "iopub.status.busy": "2024-07-15T14:58:30.244141Z",
          "iopub.status.idle": "2024-07-15T14:58:30.350138Z",
          "shell.execute_reply": "2024-07-15T14:58:30.348543Z",
          "shell.execute_reply.started": "2024-07-15T14:58:30.244472Z"
        },
        "id": "CuHPmdXJBpBC",
        "outputId": "a4265e71-eb7b-426e-f731-ef1d0a1b7660",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': 'Rice tolerance to suboptimal low temperatures relies on the maintenance of the photosynthetic capacity.\\nGazquez, A., Vilas, J. M., Colman Lerner, J. E., Maiale, S. J., Calzadilla, P. I., Menendez, A. B. and Rodriguez, A. A.\\nLaboratorio de Fisiologia de Estres Abiotico en Plantas, Unidad de Biotecnologia 1, IIB-INTECH, CONICET, UNSAM, Chascomus, Argentina.\\nCentro de Investigaciones y Desarrollo en Ciencias Aplicadas, FCEx, UNLP, Argentina.\\nDepartamento de Biodiversidad y Biologia Experimental, FCEyN - UBA, INMIBO-CONICET, Buenos Aires, Argentina.\\nLaboratorio de Fisiologia de Estres Abiotico en Plantas, Unidad de Biotecnologia 1, IIB-INTECH, CONICET, UNSAM, Chascomus, Argentina. Electronic address: andresrodriguez@conicet.gov.ar.\\nThe purpose of this research was to identify differences between two contrasting rice cultivars in their response to suboptimal low temperatures stress. A transcriptomic analysis of the seedlings was performed and results were complemented with biochemical and physiological analyses. The microarray analysis showed downregulation of many genes related with PSII and particularly with the oxygen evolving complex in the sensitive cultivar IR50. Complementary studies indicated that the PSII performance, the degree of oxygen evolving complex coupling with the PSII core and net photosynthetic rate diminished in this cultivar in response to the stress. However, the tolerant cultivar Koshihikari was able to maintain its energy equilibrium by sustaining the photosynthetic capacity. The increase of oleic acid in Koshihikari could be related with membrane remodelling of the chloroplasts and hence contribute to tolerance. Overall, these results work as a ground for future analyses that look forward to characterize possible mechanisms to tolerate this stress. How did the tolerant rice cultivar Koshihikari maintain its photosynthetic capacity under suboptimal low temperatures stress, and what possible mechanisms could contribute to its tolerance?',\n",
              " 'prompt_id': '26afb4f9bffc82fbbfdcaa8f0eec0833780e411799dceed12d639c71ce08da25',\n",
              " 'messages': [{'content': 'Rice tolerance to suboptimal low temperatures relies on the maintenance of the photosynthetic capacity.\\nGazquez, A., Vilas, J. M., Colman Lerner, J. E., Maiale, S. J., Calzadilla, P. I., Menendez, A. B. And Rodriguez, A. A.\\nLaboratorio de Fisiologia de Estres Abiotico en Plantas, Unidad de Biotecnologia 1, IIB-INTECH, CONICET, UNSAM, Chascomus, Argentina.\\nCentro de Investigaciones y Desarrollo en Ciencias Aplicadas, FCEx, UNLP, Argentina.\\nDepartamento de Biodiversidad y Biologia Experimental, FCEyN - UBA, INMIBO-CONICET, Buenos Aires, Argentina.\\nLaboratorio de Fisiologia de Estres Abiotico en Plantas, Unidad de Biotecnologia 1, IIB-INTECH, CONICET, UNSAM, Chascomus, Argentina. Electronic address: andresrodriguez@conicet.gov.ar.\\nThe purpose of this research was to identify differences between two contrasting rice cultivars in their response to suboptimal low temperatures stress. A transcriptomic analysis of the seedlings was performed and results were complemented with biochemical and physiological analyses. The microarray analysis showed downregulation of many genes related with PSII and particularly with the oxygen evolving complex in the sensitive cultivar IR50. Complementary studies indicated that the PSII performance, the degree of oxygen evolving complex coupling with the PSII core and net photosynthetic rate diminished in this cultivar in response to the stress. However, the tolerant cultivar Koshihikari was able to maintain its energy equilibrium by sustaining the photosynthetic capacity. The increase of oleic acid in Koshihikari could be related with membrane remodelling of the chloroplasts and hence contribute to tolerance. Overall, these results work as a ground for future analyses that look forward to characterize possible mechanisms to tolerate this stress. How did the tolerant rice cultivar Koshihikari maintain its photosynthetic capacity under suboptimal low temperatures stress, and what possible mechanisms could contribute to its tolerance?',\n",
              "   'role': 'user'},\n",
              "  {'content': \"The tolerant rice cultivar Koshihikari maintained its photosynthetic capacity under suboptimal low temperatures stress by sustaining its energy equilibrium. This was achieved through maintaining the activity of the photosystem II (PSII) and the coupling of the oxygen evolving complex with the PSII core, resulting in a higher net photosynthetic rate. Additionally, Koshihikari exhibited an increase in oleic acid, which could potentially contribute to membrane remodeling of chloroplasts and contribute to tolerance. Possible mechanisms that could also contribute to Koshihikari's tolerance include increased antioxidant defense mechanisms and changes in the expression of stress-responsive genes. Further research is necessary to fully understand how Koshihikari is able to tolerate suboptimal low temperatures stress and to identify potential targets for breeding programs aimed at improving rice yields under adverse environmental conditions.\",\n",
              "   'role': 'assistant'},\n",
              "  {'content': 'Can you provide more details about the biochemical and physiological analyses that were conducted in the study?',\n",
              "   'role': 'user'},\n",
              "  {'content': 'Yes, the researchers conducted several biochemical and physiological analyses in addition to the transcriptomic analysis to understand the response of the two rice cultivars to suboptimal low temperatures stress. Here are some details about these analyses:\\n\\n1. Chlorophyll fluorescence measurements: The researchers measured the chlorophyll fluorescence in the seedlings of both the tolerant and sensitive cultivars using a pulse-amplitude modulated fluorometer. This allowed them to assess the performance of the photosystem II (PSII) under stress.\\n\\n2. Oxygen evolution measurements: The researchers also measured the rate of oxygen evolution in the seedlings of both cultivars under stress conditions. This allowed them to quantify the coupling of the oxygen evolving complex with the PSII core.\\n\\n3. Net photosynthetic rate measurements: The researchers measured the net photosynthetic rate in both cultivars under stress conditions. This allowed them to assess the overall photosynthetic capacity of the plants in response to the stress.\\n\\n4. Lipid profiling: The researchers analyzed the lipid composition of the seedlings using gas chromatography-mass spectrometry (GC-MS). This allowed them to identify changes in the fatty acid composition of the plants under stress.\\n\\n5. Transcriptomic analysis: The researchers performed a genome-wide transcriptional analysis of the two rice cultivars to identify genes that were differentially expressed under suboptimal low temperatures stress conditions.\\n\\nThrough these different analyses, the researchers were able to identify differences in the response of the two rice cultivars to suboptimal low temperatures stress, particularly in their photosynthetic performance and membrane lipid composition.',\n",
              "   'role': 'assistant'},\n",
              "  {'content': \"Can you explain how the downregulation of genes related to the photosystem II (PSII) and the oxygen evolving complex affected the sensitive cultivar IR50's response to suboptimal low temperatures stress?\",\n",
              "   'role': 'user'},\n",
              "  {'content': \"Yes, the downregulation of genes related to the photosystem II (PSII) and the oxygen evolving complex had a negative effect on the sensitive cultivar IR50's response to suboptimal low temperatures stress. The PSII is a key component of the photosynthetic machinery that is responsible for capturing light and converting it into chemical energy. The oxygen evolving complex is an essential part of PSII that is involved in the splitting of water to release oxygen during photosynthesis.\\n\\nThe microarray analysis showed that many genes related to PSII and the oxygen evolving complex were downregulated in the sensitive cultivar IR50 under suboptimal low temperatures stress. This likely led to a reduction in the activity of PSII and the oxygen evolving complex, which would have limited the plant's ability to capture light energy and perform photosynthesis. This decrease in photosynthetic activity would have affected the plant's overall growth and development, making it more vulnerable to stress.\\n\\nIn contrast, the tolerant cultivar Koshihikari was able to maintain the activity of the PSII and the oxygen evolving complex under suboptimal low temperatures stress, allowing it to maintain its photosynthetic capacity and overall growth. These findings highlight the importance of maintaining the photosynthetic capacity in plants under stress conditions to ensure their survival and productivity.\",\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets['test_sft'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0pi8YdYBpBC"
      },
      "source": [
        "The dataset contains various splits, each with a certain number of rows. In our case, as we're going to do supervised fine-tuning (SFT), only the \"train_sft\" and \"test_sft\" splits are relevant for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T14:58:30.352854Z",
          "iopub.status.busy": "2024-07-15T14:58:30.352142Z",
          "iopub.status.idle": "2024-07-15T14:58:30.464390Z",
          "shell.execute_reply": "2024-07-15T14:58:30.463599Z",
          "shell.execute_reply.started": "2024-07-15T14:58:30.352815Z"
        },
        "id": "8m_-8G4CBpBC",
        "outputId": "d57269cc-3ac0-48fd-843a-3be90a4423b8",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['prompt', 'prompt_id', 'messages'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "\n",
        "indices = range(0,100) # debugging mode\n",
        "\n",
        "dataset_dict = {\"train\": raw_datasets[\"train_sft\"].select(indices),\n",
        "                \"test\": raw_datasets[\"test_sft\"].select(indices)}\n",
        "\n",
        "raw_datasets = DatasetDict(dataset_dict)\n",
        "raw_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdYCxd5SBpBC"
      },
      "source": [
        "Let's check one example. The important thing is that each example should contain a list of messages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T14:59:16.539932Z",
          "iopub.status.busy": "2024-07-15T14:59:16.538858Z",
          "iopub.status.idle": "2024-07-15T14:59:16.545298Z",
          "shell.execute_reply": "2024-07-15T14:59:16.544344Z",
          "shell.execute_reply.started": "2024-07-15T14:59:16.539896Z"
        },
        "id": "asMatg6UBpBC",
        "outputId": "2e533cc6-93fa-4477-e229-3cb3e1e789d2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['prompt', 'prompt_id', 'messages'])\n"
          ]
        }
      ],
      "source": [
        "example = raw_datasets[\"train\"][0]\n",
        "print(example.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jjVjtC_BpBD"
      },
      "source": [
        "Each message is a dictionary containing 2 keys, namely:\n",
        "\n",
        "* \"role\": specifies who the creator of the message is (could be \"system\", \"assistant\" or \"user\" - the latter referring to a human).\n",
        "* \"content\": the actual content of the message.\n",
        "\n",
        "Let's print out the sequence of messages for this training example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T14:58:30.526922Z",
          "iopub.status.busy": "2024-07-15T14:58:30.526619Z",
          "iopub.status.idle": "2024-07-15T14:58:30.610415Z",
          "shell.execute_reply": "2024-07-15T14:58:30.609245Z",
          "shell.execute_reply.started": "2024-07-15T14:58:30.526896Z"
        },
        "id": "4KBW9QmDBpBD",
        "outputId": "0975f52b-2b91-407a-a0c9-b25c6b2ad331",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user                :  These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\n",
            "On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\n",
            "Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\n",
            "Does this feature apply to all sections of the theme or just specific ones as listed in the text material?\n",
            "##########\n",
            "assistant           :  This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.\n",
            "##########\n",
            "user                :  Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?\n",
            "##########\n",
            "assistant           :  Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n",
            "\n",
            "1. Log in to your Shopify account and go to your Online Store.\n",
            "2. Click on Customize theme for the section-based theme you are using.\n",
            "3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n",
            "4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n",
            "5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n",
            "6. If available, select 'Show secondary image on hover'.\n",
            "7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n",
            "\n",
            "If you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.\n",
            "##########\n",
            "user                :  Can you provide me with a link to the documentation for my theme?\n",
            "##########\n",
            "assistant           :  I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.\n",
            "##########\n",
            "user                :  Can you confirm if this feature also works for the Quick Shop section of my theme?\n",
            "##########\n",
            "assistant           :  The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n",
            "\n",
            "1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.\n",
            "##########\n"
          ]
        }
      ],
      "source": [
        "messages = example[\"messages\"]\n",
        "for message in messages:\n",
        "  role = message[\"role\"]\n",
        "  content = message[\"content\"]\n",
        "  print('{0:20}:  {1}'.format(role, content))\n",
        "  print('#'*10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8rOA_DKBpBD"
      },
      "source": [
        "## Load tokenizer\n",
        "Next, we instantiate the tokenizer, which is required to prepare the text for the model. The model doesn't directly take strings as input, but rather `input_ids`, which represent integer indices in the vocabulary of a Transformer model.\n",
        "\n",
        "- the padding token ID.\n",
        "during fine-tuning, we will need to pad the (instruction, completion) pairs in order to create batches of equal length.\n",
        "\n",
        "- the model max length: this is required in order to truncate sequences which are too long for the model. Here we decide to train on at most 2048 tokens.\n",
        "\n",
        "the chat template. A [chat template](https://huggingface.co/blog/chat-templates) determines how each list of messages is turned into a tokenizable string, by adding special strings in between such as `<|user|>` to indicate a user message and `<|assistant|>` to indicate the chatbot's response. Here we define the default chat template, used by most chat models. See also the [docs](https://huggingface.co/docs/transformers/main/en/chat_templating)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-15T14:59:22.595182Z",
          "iopub.status.busy": "2024-07-15T14:59:22.594734Z",
          "iopub.status.idle": "2024-07-15T14:59:22.599818Z",
          "shell.execute_reply": "2024-07-15T14:59:22.598721Z",
          "shell.execute_reply.started": "2024-07-15T14:59:22.595149Z"
        },
        "id": "tOAJJBQkBpBD",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCdnN1tIKly5",
        "outputId": "1a740ea3-48fd-44a5-90c0-4926fd262446"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--google--gemma-2b/snapshots/68e273d91b1d6ea57c9e6024c4f887832f7b43fa/tokenizer.model\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--gemma-2b/snapshots/68e273d91b1d6ea57c9e6024c4f887832f7b43fa/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--google--gemma-2b/snapshots/68e273d91b1d6ea57c9e6024c4f887832f7b43fa/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--google--gemma-2b/snapshots/68e273d91b1d6ea57c9e6024c4f887832f7b43fa/tokenizer_config.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1000000000000000019884624838656"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id='google/gemma-2b' #Could not tune it in 16 GB ram\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,token=token,trust_remote_code=True)\n",
        "tokenizer.model_max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-15T15:02:21.888149Z",
          "iopub.status.busy": "2024-07-15T15:02:21.887721Z",
          "iopub.status.idle": "2024-07-15T15:02:22.896625Z",
          "shell.execute_reply": "2024-07-15T15:02:22.895806Z",
          "shell.execute_reply.started": "2024-07-15T15:02:21.888115Z"
        },
        "id": "qVvHGLtOBpBD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# set pad_token_id equal to the eos_token_id if not set\n",
        "if tokenizer.pad_token_id is None:\n",
        "  tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Set reasonable default for models without max length\n",
        "if tokenizer.model_max_length > 100_000:\n",
        "  tokenizer.model_max_length = 2048\n",
        "\n",
        "# Set chat template\n",
        "DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n",
        "tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntE9ejIdBpBD",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22s5DSK0BpBD"
      },
      "source": [
        "## Apply chat template\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-15T15:00:07.196068Z",
          "iopub.status.busy": "2024-07-15T15:00:07.195354Z",
          "iopub.status.idle": "2024-07-15T15:00:07.200375Z",
          "shell.execute_reply": "2024-07-15T15:00:07.199253Z",
          "shell.execute_reply.started": "2024-07-15T15:00:07.196036Z"
        },
        "id": "8I5OL8xCBpBD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "from multiprocessing import cpu_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-15T15:00:09.394205Z",
          "iopub.status.busy": "2024-07-15T15:00:09.393561Z",
          "iopub.status.idle": "2024-07-15T15:00:09.399705Z",
          "shell.execute_reply": "2024-07-15T15:00:09.398689Z",
          "shell.execute_reply.started": "2024-07-15T15:00:09.394171Z"
        },
        "id": "b9mxFd-XBpBE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def apply_chat_template(example,tokenizer):\n",
        "    messages = example[\"messages\"]\n",
        "    # We add an empty system message if there is none\n",
        "    if messages[0][\"role\"] != \"system\":\n",
        "        messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
        "    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "\n",
        "    return example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "c61407d60ce04aba8f7e79ce340a73e1",
            "df25bc99948b4b709c7a7063649b9728",
            "c46299d0393c4f7a8f56d5d66f021028",
            "e7c3649b75c54d34ae25578361c933cc",
            "49f19f485d1342c49d92f2ed30d3d169",
            "a4f3d79fea2848a3814bec3447538a18",
            "142c736c045646f48d65e04293ceda4a",
            "f14a89a5cefb4d8ab3f1f1e912581973",
            "c15d66cc645b499cb8bd33e3fb3d05b3",
            "b6c8a53045424ee68f3ba08a09f5d2bb",
            "3d662190723a4691ae2c9b55e7deccb5",
            "d733ad5c41214c80a9497e0dd156e5e3",
            "2b7a6c82a061432da3e406b3855627c1",
            "6c6c155e787e45bb849dbe3036e3e92a",
            "88454d58b79245eb8fc58231a0e0d390",
            "d46ad103bcca474f9a59463798944b19",
            "fd559df5929c46a09fa844704dfbe4a6",
            "114d783d4bce4862a72249b780b5c2c6",
            "71bce570c2ab4e24b4b4f8c376604c54",
            "6b3521c5b9c64a25846f98e7fc971950",
            "8790db6dcf524dcbb4e1bf644b71f745",
            "31e3a60644c54604ab01bd4491e472a1"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T15:00:16.825927Z",
          "iopub.status.busy": "2024-07-15T15:00:16.825558Z",
          "iopub.status.idle": "2024-07-15T15:00:25.434700Z",
          "shell.execute_reply": "2024-07-15T15:00:25.433617Z",
          "shell.execute_reply.started": "2024-07-15T15:00:16.825896Z"
        },
        "id": "QQsVwW-lBpBE",
        "outputId": "39a0e7ba-d6d6-4d86-983d-c3fab50d8ae1",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c61407d60ce04aba8f7e79ce340a73e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template (num_proc=2):   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d733ad5c41214c80a9497e0dd156e5e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template (num_proc=2):   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "column_names = list(raw_datasets[\"train\"].features)\n",
        "\n",
        "\n",
        "raw_datasets = raw_datasets.map(apply_chat_template,\n",
        "                                num_proc=cpu_count(),\n",
        "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
        "                                remove_columns=column_names,\n",
        "                                desc=\"Applying chat template\",)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T15:00:29.559591Z",
          "iopub.status.busy": "2024-07-15T15:00:29.559199Z",
          "iopub.status.idle": "2024-07-15T15:00:29.566959Z",
          "shell.execute_reply": "2024-07-15T15:00:29.566069Z",
          "shell.execute_reply.started": "2024-07-15T15:00:29.559559Z"
        },
        "id": "ytD0bjlhBpBE",
        "outputId": "bf8acbab-f54c-4873-b919-3b38377ea7ca",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample 81 of the processed training set:\n",
            "\n",
            "<|system|>\n",
            "<|endoftext|>\n",
            "<|user|>\n",
            "Write a JavaScript function that takes in one parameter and checks if that parameter is a perfect square. The function should return a boolean value - true if the parameter is a perfect square and false otherwise. You should test your function using a range of inputs and provide the output for each test case.<|endoftext|>\n",
            "<|assistant|>\n",
            "```\n",
            "function isPerfectSquare(num) {\n",
            "  if (num < 0) {\n",
            "    return false;\n",
            "  }\n",
            "  else if (Math.sqrt(num) === Math.floor(Math.sqrt(num))) {\n",
            "    return true;\n",
            "  }\n",
            "  else {\n",
            "    return false;\n",
            "  }\n",
            "}\n",
            "\n",
            "console.log(isPerfectSquare(16)); // true\n",
            "console.log(isPerfectSquare(25)); // true\n",
            "console.log(isPerfectSquare(144)); // true\n",
            "console.log(isPerfectSquare(7)); // false\n",
            "console.log(isPerfectSquare(-25)); // false\n",
            "```<|endoftext|>\n",
            "<|user|>\n",
            "Great, the function looks good! Can you add some comments to explain what each line of code is doing?<|endoftext|>\n",
            "<|assistant|>\n",
            "Sure, here is the updated function with comments:\n",
            "\n",
            "```\n",
            "function isPerfectSquare(num) {\n",
            "  if (num < 0) { // check if the number is negative\n",
            "    return false;\n",
            "  }\n",
            "  else if (Math.sqrt(num) === Math.floor(Math.sqrt(num))) { // calculate the square root of num and check if it is a whole number\n",
            "    return true; // if it is a whole number, return true\n",
            "  }\n",
            "  else {\n",
            "    return false; // otherwise, return false\n",
            "  }\n",
            "}\n",
            "\n",
            "// testing the function with different inputs\n",
            "console.log(isPerfectSquare(16)); // true\n",
            "console.log(isPerfectSquare(25)); // true\n",
            "console.log(isPerfectSquare(144)); // true\n",
            "console.log(isPerfectSquare(7)); // false\n",
            "console.log(isPerfectSquare(-25)); // false\n",
            "```\n",
            "\n",
            "I hope this helps!<|endoftext|>\n",
            "\n",
            "Sample 14 of the processed training set:\n",
            "\n",
            "<|system|>\n",
            "<|endoftext|>\n",
            "<|user|>\n",
            "Write step-by-step instructions for making a traditional snowman using three large snowballs, including information on how to properly pack the snow, tools (if applicable), and recommended size ratios for each snowball. Be sure to include any additional details on decorations or accessories, if desired.<|endoftext|>\n",
            "<|assistant|>\n",
            "Step 1: Find a suitable location for building the snowman. Look for a large, flat area with plenty of snow.\n",
            "\n",
            "Step 2: Start by packing the first snowball. Roll a large ball of snow, about shoulder height in size. Roll the snowball around in the snow, covering it thoroughly, and packing the snow tightly as you go. Keep rolling until the snowball is smooth and even in shape. This will form the base of your snowman.\n",
            "\n",
            "Step 3: Repeat Step 2 to make the second and third snowballs. The second snowball should be slightly smaller than the first one (about waist height), and the third snowball should be even smaller (about knee height). Make sure each snowball is packed tightly and covered evenly in snow.\n",
            "\n",
            "Step 4: Once you have all three snowballs ready, lift the second snowball onto the first one. Use your hands to press the two snowballs together until they stick together firmly. You can use a shovel to lift the snowball if it's too heavy to lift by hand.\n",
            "\n",
            "Step 5: Next, press the third snowball on top of the second one. Make sure it is centered and sits evenly on top of the other two snowballs. Press it down firmly onto the second snowball to keep it in place.\n",
            "\n",
            "Step 6: Now it's time to add character to your snowman. Use twigs or branches for its arms, and add a hat and scarf for a cozy look. You can use buttons or rocks for the eyes, and a carrot for its nose. Get creative and use whatever materials you have available.\n",
            "\n",
            "Step 7: Finally, step back and admire your creation! You've successfully built a traditional snowman using three large snowballs.<|endoftext|>\n",
            "<|user|>\n",
            "It looks easy enough, but can you provide more details on how to pack the snow properly? Do I need to use my hands, or can I use a tool?<|endoftext|>\n",
            "<|assistant|>\n",
            "Packing the snow properly is crucial for building a sturdy snowman. You can use your hands or a tool, such as a shovel or a wooden block, to pack the snow tightly. Here are some tips for packing the snow:\n",
            "\n",
            "- Use dense, compacted snow for building the snowballs. Avoid using dry, powdery snow, as it won't stick together well. - Start by rolling a small snowball and then gradually add more snow as you roll. This will help ensure that the snow is packed evenly and tightly. - Use your hands or a tool to press the snow together firmly. Make sure there are no air pockets or gaps in the snowball, as this can cause it to collapse. - Roll the snowball in all directions to create a round and smooth shape. If the snowball becomes lopsided, gently push it back into shape. - As you roll the snowball, add more snow occasionally to ensure that it remains larger than the previous snowball. This will help create the classic snowman shape with a wider base and a narrower top. Remember, building a snowman is all about having fun, so don't worry too much about getting everything perfect. Just enjoy the process and let your creativity guide you!<|endoftext|>\n",
            "<|user|>\n",
            "Can you also give me some ideas on how to decorate the snowman with materials other than branches and carrots? Something more unusual perhaps?<|endoftext|>\n",
            "<|assistant|>\n",
            "Absolutely! There are many creative and unusual ways to decorate a snowman. Here are some ideas to inspire you:\n",
            "\n",
            "1. Use old clothes: Rather than just settling for a hat and scarf, you could dress up your snowman in an old coat, pants, or even a tie. Be sure to use clothes that aren't needed anymore and wash them before using to prevent staining the snow. 2. Add some color: Mix food coloring with water and fill spray bottles. You could spray your snowman with different colors. This will give it an eye-catching look as it sticks to the snow. 3. Use household items: You can create a unique snowman by utilizing household items such as CDs, paper towel tubes, or even plastic lids. Using a sturdy adhesive like duct tape, hot glue, or super glue, you could add these items to create a face, eyes, or nose. 4. Get creative with eyes and nose: Instead of using traditional items like coal and carrot for eyes and nose, get creative. Use jam jar lids or orange slices to create eyes, or pine cones for the nose. 5. Let your imagination run wild: The sky is the limit when decorating a snowman. You could add any other accessory that you like, such as hats, sunglasses or without any accessories, too. Try something new and exciting that will make your snowman stand out. Remember, decorating the snowman is where you have to let your imagination run wild. The idea is to get creative and have fun!<|endoftext|>\n",
            "\n",
            "Sample 3 of the processed training set:\n",
            "\n",
            "<|system|>\n",
            "<|endoftext|>\n",
            "<|user|>\n",
            "De León, previewing the speech he will give today, said he will highlight his Senate Bill 535, which directs a quarter of the proceeds from the Greenhouse Gas Reduction Fund to projects that benefit disadvantaged communities.\n",
            "On Thursday, de León nodded approvingly as a string of leading scientists and religious leaders gathered for hours of weedy policy discussions on the impacts of climate change, including gloomy predictions on mortality attributable to air pollution.\n",
            "SEIU HEADS TO THE BAR: Employees of the State Bar of California represented by SEIU are planning a picket line today at the bar building in Los Angeles to protest the latest contract offer. What is the reason for SEIU employees planning a picket line at the State Bar of California building in Los Angeles?<|endoftext|>\n",
            "<|assistant|>\n",
            "The reason for SEIU employees planning a picket line at the State Bar of California building in Los Angeles is to protest the latest contract offer.<|endoftext|>\n",
            "<|user|>\n",
            "Can you provide more details about Senate Bill 535 and how it will benefit disadvantaged communities?<|endoftext|>\n",
            "<|assistant|>\n",
            "Sure, Senate Bill 535 is a California law that directs at least 25% of the money generated through the state's Greenhouse Gas Reduction Fund towards projects that benefit disadvantaged communities. The bill is designed to ensure that the benefits of California's climate policies, which include cap-and-trade, are felt most heavily by communities that have been disproportionately impacted by pollution and environmental degradation.\n",
            "\n",
            "The funds generated through the bill are invested in projects that promote clean energy, reduce pollution, and support sustainable communities. This includes initiatives like public transportation, energy efficiency retrofits for low-income homes, and urban forestry projects.\n",
            "\n",
            "Proponents of the bill argue that it helps to level the playing field for low-income communities and communities of color, which have historically faced greater exposure to environmental hazards and pollution. By directing funds towards these communities, the bill aims to create more equitable and sustainable outcomes for all Californians.<|endoftext|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create the splits\n",
        "train_dataset = raw_datasets[\"train\"]\n",
        "eval_dataset = raw_datasets[\"test\"]\n",
        "\n",
        "for index in random.sample(range(len(raw_datasets[\"train\"])), 3):\n",
        "  print(f\"Sample {index} of the processed training set:\\n\\n{raw_datasets['train'][index]['text']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSO7jnwBBpBE",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T15:00:38.037061Z",
          "iopub.status.busy": "2024-07-15T15:00:38.036356Z",
          "iopub.status.idle": "2024-07-15T15:00:38.043312Z",
          "shell.execute_reply": "2024-07-15T15:00:38.042566Z",
          "shell.execute_reply.started": "2024-07-15T15:00:38.037028Z"
        },
        "id": "GK2feii4BpBE",
        "outputId": "28eaa2a2-9d89-4222-9712-9638eddbd285",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfv-fdYpBpBE"
      },
      "source": [
        "## Define model arguments\n",
        "\n",
        "Next, it's time to define the model arguments.\n",
        "\n",
        "Here, some explanation is required regarding ways to fine-tune model.\n",
        "\n",
        "### Full fine-tuning\n",
        "\n",
        "Typically, one performs \"full fine-tuning\": this means that we will simply update all the weights of the base model during fine-tuning. This is then typically done either in full precision (float32), or mixed precision (a combination of float32 and float16). However, with ever larger models like LLMs, this becomes infeasible.\n",
        "\n",
        "\n",
        "### LoRa, a PEFT method\n",
        "\n",
        "Hence, some clever people at Microsoft have come up with a method called [LoRa](https://huggingface.co/docs/peft/conceptual_guides/lora) (low-rank adaptation). The idea here is that, rather than performing full fine-tuning, we are going to freeze the existing model and only add a few parameter weights to the model (called \"adapters\"), which we're going to train.\n",
        "\n",
        "LoRa is what we call a parameter-efficient fine-tuning (PEFT) method. It's a popular method for fine-tuning models in a parameter-efficient way, by only training a few adapters, keeping the existing model untouched\n",
        "\n",
        "### QLoRa, an even more efficient method\n",
        "\n",
        "With regular LoRa, one would keep the base model in 32 or 16 bits in memory, and then train the parameter weights. However, there have been new methods developed to shrink the size of a model considerably, to 8 or 4 bits per parameter (we call this [\"quantization\"](https://huggingface.co/docs/transformers/main_classes/quantization)). Hence, if we apply LoRa to a quantized model (like a 4-bit model), then we call this QLoRa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-15T15:00:42.503062Z",
          "iopub.status.busy": "2024-07-15T15:00:42.502331Z",
          "iopub.status.idle": "2024-07-15T15:00:55.559566Z",
          "shell.execute_reply": "2024-07-15T15:00:55.558560Z",
          "shell.execute_reply.started": "2024-07-15T15:00:42.503032Z"
        },
        "id": "ykzgX3LYBpBE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from peft import LoraConfig\n",
        "from transformers import TrainingArguments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T15:00:55.562305Z",
          "iopub.status.busy": "2024-07-15T15:00:55.561440Z",
          "iopub.status.idle": "2024-07-15T15:00:55.596175Z",
          "shell.execute_reply": "2024-07-15T15:00:55.595190Z",
          "shell.execute_reply.started": "2024-07-15T15:00:55.562268Z"
        },
        "id": "OUAQUQTjBpBE",
        "outputId": "a6ffef03-cfc1-4e18-aabe-ab2a73666146",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'': 0}"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BitsAndBytesConfig , AutoModelForCausalLM\n",
        "import torch\n",
        "device_map = {\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n",
        "device_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-15T15:08:00.125382Z",
          "iopub.status.busy": "2024-07-15T15:08:00.124548Z",
          "iopub.status.idle": "2024-07-15T15:08:00.129731Z",
          "shell.execute_reply": "2024-07-15T15:08:00.128818Z",
          "shell.execute_reply.started": "2024-07-15T15:08:00.125350Z"
        },
        "id": "cTTr4nufBpBF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from huggingface_hub.hf_api import HfFolder\n",
        "HfFolder.save_token(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFrVUaPaNgXu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTGT_B_sIy__"
      },
      "outputs": [],
      "source": [
        "#  for n, _ in model.named_parameters():\n",
        "#     if not n.endswith(\"bias\"):\n",
        "#         print(n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992,
          "referenced_widgets": [
            "8ba814c20f5342a8893f1b26a9fef82f",
            "18e070c9b54d4013822f06a65d2404bb",
            "3de508a5f5d74fd28d25a8b667d60bf8",
            "0f1158c9f5a441658bdbb7743fb6ae16",
            "8a540cb1f50349ffa3e19261dc993f4c",
            "e6f46e965b9240a888f95a1513577a47",
            "9bffe8b7534342cd865830944e9458d4",
            "cd78e9e2d0054a869e0d07e9a1310c06",
            "98a5d1e7df314e5680da3eb99d2b0d8f",
            "9d8f16e4f1bb4cf39ff751d92a84d464",
            "82339ce38dde42e78e8fce7f58792f4f"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T15:25:59.525096Z",
          "iopub.status.busy": "2024-07-15T15:25:59.524351Z",
          "iopub.status.idle": "2024-07-15T15:25:59.531797Z",
          "shell.execute_reply": "2024-07-15T15:25:59.530922Z",
          "shell.execute_reply.started": "2024-07-15T15:25:59.525061Z"
        },
        "id": "24ayI2ShBpBF",
        "outputId": "260c5d47-5db2-48eb-c7e0-3b09433dea65",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--gemma-2b/snapshots/68e273d91b1d6ea57c9e6024c4f887832f7b43fa/config.json\n",
            "Model config GemmaConfig {\n",
            "  \"_name_or_path\": \"google/gemma-2b\",\n",
            "  \"architectures\": [\n",
            "    \"GemmaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"head_dim\": 256,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_activation\": null,\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"model_type\": \"gemma\",\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 18,\n",
            "  \"num_key_value_heads\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.41.2\",\n",
            "  \"use_cache\": false,\n",
            "  \"vocab_size\": 256000\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--google--gemma-2b/snapshots/68e273d91b1d6ea57c9e6024c4f887832f7b43fa/model.safetensors.index.json\n",
            "Will use torch_dtype=torch.bfloat16 as defined in model's config object\n",
            "Instantiating GemmaForCausalLM model under default dtype torch.bfloat16.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 2,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"use_cache\": false\n",
            "}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ba814c20f5342a8893f1b26a9fef82f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing GemmaForCausalLM.\n",
            "\n",
            "All the weights of GemmaForCausalLM were initialized from the model checkpoint at google/gemma-2b.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GemmaForCausalLM for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--gemma-2b/snapshots/68e273d91b1d6ea57c9e6024c4f887832f7b43fa/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 2,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# specify how to quantize the model\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "model_kwargs = dict(\n",
        "    #attn_implementation=\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n",
        "    torch_dtype=\"auto\",\n",
        "    use_cache=False, # set to False as we're going to use gradient checkpointing\n",
        "    device_map=device_map,\n",
        "    #hidden_activation=True,\n",
        "    quantization_config=quantization_config,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id,**model_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkrLED9oFQX3"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T15:26:02.981354Z",
          "iopub.status.busy": "2024-07-15T15:26:02.980969Z",
          "iopub.status.idle": "2024-07-15T15:26:03.014600Z",
          "shell.execute_reply": "2024-07-15T15:26:03.013886Z",
          "shell.execute_reply.started": "2024-07-15T15:26:02.981323Z"
        },
        "id": "dzHiEJwiBpBF",
        "outputId": "96d083f3-002f-442b-9953-59f25a1fb6b4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "from json import JSONEncoder\n",
        "\n",
        "# path where the Trainer will save its checkpoints and logs\n",
        "output_dir = 'data/gemma-2b-sft-lora'\n",
        "\n",
        "# based on config\n",
        "training_args = TrainingArguments(\n",
        "    fp16=True, # specify bf16=True instead when training on GPUs that support bf16\n",
        "    do_eval=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    gradient_accumulation_steps=128,\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    learning_rate=2.0e-05,\n",
        "    log_level=\"info\",\n",
        "    logging_steps=5,\n",
        "    logging_strategy=\"steps\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    max_steps=-1,\n",
        "    num_train_epochs=1,\n",
        "    output_dir=output_dir,\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_eval_batch_size=1, # originally set to 8\n",
        "    per_device_train_batch_size=1, # originally set to 8\n",
        "    # push_to_hub=True,\n",
        "    # hub_model_id=\"gemma-2b-sft-lora\",\n",
        "    # hub_strategy=\"every_save\",\n",
        "    # report_to=\"tensorboard\",\n",
        "    save_strategy=\"no\",\n",
        "    save_total_limit=None,\n",
        "    seed=42,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-15T15:26:08.449581Z",
          "iopub.status.busy": "2024-07-15T15:26:08.449204Z",
          "iopub.status.idle": "2024-07-15T15:26:08.454757Z",
          "shell.execute_reply": "2024-07-15T15:26:08.453777Z",
          "shell.execute_reply.started": "2024-07-15T15:26:08.449551Z"
        },
        "id": "aEQbiDSeBpBF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(\n",
        "        r=64,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385,
          "referenced_widgets": [
            "562e0bcfff1241be944a93169bde5f18",
            "1d463c27a13c4013854367a708dd1baf",
            "0e7e1ac50d114827ada563ea3957a7fe",
            "32faff73bc384aa9b1027a607356887e",
            "697a4840699045f5933f0d1d890e98cf",
            "38ba75b01fa6484e9382fe2a76dd7881",
            "9b24e55558de45e69be61cc6f11e35bb",
            "fd07695531324da38889c41d41a59f52",
            "bf7c1dbaeb354e18b34e0754f82a71d8",
            "639d63f5f1484f1c93a4921f13ce6086",
            "9ed176aeca124b6da73a1fffccfc6c37",
            "62007cb9fb5e40beaf03816310a2c32b",
            "daf44b63f92a41f381367f3793f0a79c",
            "d7d8f729f39e4300958347d979481b6e",
            "9a4f318efe0346b899a820dd30bd0d77",
            "c3b5d0b1964942c09f0b1207067f9e6c",
            "322dcaf0ae134f278c78603cf6abc01f",
            "4d3ddfc558974da7b757da2761b74790",
            "9e2f14006b7b41f19a9dad5917b39c9d",
            "a7d2bf92d91b4757a02d923d045a1560",
            "9ddc3aa312c5464a843d82fe30057d84",
            "4bd5f856fa72432d80f22b86e2ec5f47"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T15:26:09.691667Z",
          "iopub.status.busy": "2024-07-15T15:26:09.690484Z",
          "iopub.status.idle": "2024-07-15T15:26:14.209590Z",
          "shell.execute_reply": "2024-07-15T15:26:14.208742Z",
          "shell.execute_reply.started": "2024-07-15T15:26:09.691619Z"
        },
        "id": "C-RwFoWBBpBF",
        "outputId": "bfec2aca-dd05-46a3-f4f9-2b6b02d5afe3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, packing, max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "PyTorch: setting up devices\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:192: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "PyTorch: setting up devices\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "562e0bcfff1241be944a93169bde5f18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3071 > 2048). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62007cb9fb5e40beaf03816310a2c32b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:408: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "Using auto half precision backend\n"
          ]
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        dataset_text_field=\"text\",\n",
        "        tokenizer=tokenizer,\n",
        "        packing=True,\n",
        "        peft_config=peft_config,\n",
        "        max_seq_length=tokenizer.model_max_length,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "execution": {
          "iopub.execute_input": "2024-07-15T15:27:02.025491Z",
          "iopub.status.busy": "2024-07-15T15:27:02.025048Z",
          "iopub.status.idle": "2024-07-15T15:27:02.903523Z",
          "shell.execute_reply": "2024-07-15T15:27:02.902032Z",
          "shell.execute_reply.started": "2024-07-15T15:27:02.025458Z"
        },
        "id": "X6JIFzwzBpBF",
        "outputId": "534a0c08-8491-4ef9-8f24-37969dc7e9ab",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 61\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 128\n",
            "  Total optimization steps = 1\n",
            "  Number of trainable parameters = 14,745,600\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1.95 GiB. GPU ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-a6eca412ee9e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trl_activate_neftune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;31m# After training we make sure to retrieve back the original forward pass method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1885\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1886\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2216\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3248\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3249\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2145\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2148\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.95 GiB. GPU "
          ]
        }
      ],
      "source": [
        "train_result = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-15T15:08:45.466884Z",
          "iopub.status.idle": "2024-07-15T15:08:45.467235Z",
          "shell.execute_reply": "2024-07-15T15:08:45.467086Z",
          "shell.execute_reply.started": "2024-07-15T15:08:45.467071Z"
        },
        "id": "0XK-RJ13BpBF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka40jAaOBpBF"
      },
      "outputs": [],
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"\"\"\\ntrainable model parameters:{trainable_model_params}\n",
        "                all model parameters: {all_model_params}\n",
        "                percentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7ophtZmJ65c",
        "outputId": "ed0d9905-86fa-41b5-909e-86db5c5cdefe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PEFT model parameters to be updated:\n",
            "\n",
            "trainable model parameters:14745600\n",
            "                all model parameters: 1530013696\n",
            "                percentage of trainable model parameters: 0.96%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f'PEFT model parameters to be updated:\\n{print_number_of_trainable_model_parameters(trainer.model)}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jxmv2WVKCZT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30747,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e7e1ac50d114827ada563ea3957a7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd07695531324da38889c41d41a59f52",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf7c1dbaeb354e18b34e0754f82a71d8",
            "value": 1
          }
        },
        "0f1158c9f5a441658bdbb7743fb6ae16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8f16e4f1bb4cf39ff751d92a84d464",
            "placeholder": "​",
            "style": "IPY_MODEL_82339ce38dde42e78e8fce7f58792f4f",
            "value": " 2/2 [00:18&lt;00:00,  7.92s/it]"
          }
        },
        "114d783d4bce4862a72249b780b5c2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "142c736c045646f48d65e04293ceda4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18e070c9b54d4013822f06a65d2404bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6f46e965b9240a888f95a1513577a47",
            "placeholder": "​",
            "style": "IPY_MODEL_9bffe8b7534342cd865830944e9458d4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1d463c27a13c4013854367a708dd1baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38ba75b01fa6484e9382fe2a76dd7881",
            "placeholder": "​",
            "style": "IPY_MODEL_9b24e55558de45e69be61cc6f11e35bb",
            "value": "Generating train split: "
          }
        },
        "2b7a6c82a061432da3e406b3855627c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd559df5929c46a09fa844704dfbe4a6",
            "placeholder": "​",
            "style": "IPY_MODEL_114d783d4bce4862a72249b780b5c2c6",
            "value": "Applying chat template (num_proc=2): 100%"
          }
        },
        "31e3a60644c54604ab01bd4491e472a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "322dcaf0ae134f278c78603cf6abc01f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32faff73bc384aa9b1027a607356887e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_639d63f5f1484f1c93a4921f13ce6086",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed176aeca124b6da73a1fffccfc6c37",
            "value": " 61/0 [00:00&lt;00:00,  1.88 examples/s]"
          }
        },
        "38ba75b01fa6484e9382fe2a76dd7881": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d662190723a4691ae2c9b55e7deccb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3de508a5f5d74fd28d25a8b667d60bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd78e9e2d0054a869e0d07e9a1310c06",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98a5d1e7df314e5680da3eb99d2b0d8f",
            "value": 2
          }
        },
        "49f19f485d1342c49d92f2ed30d3d169": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bd5f856fa72432d80f22b86e2ec5f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d3ddfc558974da7b757da2761b74790": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "562e0bcfff1241be944a93169bde5f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d463c27a13c4013854367a708dd1baf",
              "IPY_MODEL_0e7e1ac50d114827ada563ea3957a7fe",
              "IPY_MODEL_32faff73bc384aa9b1027a607356887e"
            ],
            "layout": "IPY_MODEL_697a4840699045f5933f0d1d890e98cf"
          }
        },
        "62007cb9fb5e40beaf03816310a2c32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_daf44b63f92a41f381367f3793f0a79c",
              "IPY_MODEL_d7d8f729f39e4300958347d979481b6e",
              "IPY_MODEL_9a4f318efe0346b899a820dd30bd0d77"
            ],
            "layout": "IPY_MODEL_c3b5d0b1964942c09f0b1207067f9e6c"
          }
        },
        "639d63f5f1484f1c93a4921f13ce6086": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "697a4840699045f5933f0d1d890e98cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b3521c5b9c64a25846f98e7fc971950": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c6c155e787e45bb849dbe3036e3e92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71bce570c2ab4e24b4b4f8c376604c54",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b3521c5b9c64a25846f98e7fc971950",
            "value": 100
          }
        },
        "71bce570c2ab4e24b4b4f8c376604c54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82339ce38dde42e78e8fce7f58792f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8790db6dcf524dcbb4e1bf644b71f745": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88454d58b79245eb8fc58231a0e0d390": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8790db6dcf524dcbb4e1bf644b71f745",
            "placeholder": "​",
            "style": "IPY_MODEL_31e3a60644c54604ab01bd4491e472a1",
            "value": " 100/100 [00:00&lt;00:00,  2.68 examples/s]"
          }
        },
        "8a540cb1f50349ffa3e19261dc993f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ba814c20f5342a8893f1b26a9fef82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18e070c9b54d4013822f06a65d2404bb",
              "IPY_MODEL_3de508a5f5d74fd28d25a8b667d60bf8",
              "IPY_MODEL_0f1158c9f5a441658bdbb7743fb6ae16"
            ],
            "layout": "IPY_MODEL_8a540cb1f50349ffa3e19261dc993f4c"
          }
        },
        "98a5d1e7df314e5680da3eb99d2b0d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a4f318efe0346b899a820dd30bd0d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ddc3aa312c5464a843d82fe30057d84",
            "placeholder": "​",
            "style": "IPY_MODEL_4bd5f856fa72432d80f22b86e2ec5f47",
            "value": " 59/0 [00:00&lt;00:00,  2.67 examples/s]"
          }
        },
        "9b24e55558de45e69be61cc6f11e35bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bffe8b7534342cd865830944e9458d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d8f16e4f1bb4cf39ff751d92a84d464": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ddc3aa312c5464a843d82fe30057d84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e2f14006b7b41f19a9dad5917b39c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9ed176aeca124b6da73a1fffccfc6c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f3d79fea2848a3814bec3447538a18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d2bf92d91b4757a02d923d045a1560": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6c8a53045424ee68f3ba08a09f5d2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7c1dbaeb354e18b34e0754f82a71d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c15d66cc645b499cb8bd33e3fb3d05b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3b5d0b1964942c09f0b1207067f9e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46299d0393c4f7a8f56d5d66f021028": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f14a89a5cefb4d8ab3f1f1e912581973",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c15d66cc645b499cb8bd33e3fb3d05b3",
            "value": 100
          }
        },
        "c61407d60ce04aba8f7e79ce340a73e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df25bc99948b4b709c7a7063649b9728",
              "IPY_MODEL_c46299d0393c4f7a8f56d5d66f021028",
              "IPY_MODEL_e7c3649b75c54d34ae25578361c933cc"
            ],
            "layout": "IPY_MODEL_49f19f485d1342c49d92f2ed30d3d169"
          }
        },
        "cd78e9e2d0054a869e0d07e9a1310c06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d46ad103bcca474f9a59463798944b19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d733ad5c41214c80a9497e0dd156e5e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b7a6c82a061432da3e406b3855627c1",
              "IPY_MODEL_6c6c155e787e45bb849dbe3036e3e92a",
              "IPY_MODEL_88454d58b79245eb8fc58231a0e0d390"
            ],
            "layout": "IPY_MODEL_d46ad103bcca474f9a59463798944b19"
          }
        },
        "d7d8f729f39e4300958347d979481b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e2f14006b7b41f19a9dad5917b39c9d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7d2bf92d91b4757a02d923d045a1560",
            "value": 1
          }
        },
        "daf44b63f92a41f381367f3793f0a79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_322dcaf0ae134f278c78603cf6abc01f",
            "placeholder": "​",
            "style": "IPY_MODEL_4d3ddfc558974da7b757da2761b74790",
            "value": "Generating train split: "
          }
        },
        "df25bc99948b4b709c7a7063649b9728": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f3d79fea2848a3814bec3447538a18",
            "placeholder": "​",
            "style": "IPY_MODEL_142c736c045646f48d65e04293ceda4a",
            "value": "Applying chat template (num_proc=2): 100%"
          }
        },
        "e6f46e965b9240a888f95a1513577a47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c3649b75c54d34ae25578361c933cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6c8a53045424ee68f3ba08a09f5d2bb",
            "placeholder": "​",
            "style": "IPY_MODEL_3d662190723a4691ae2c9b55e7deccb5",
            "value": " 100/100 [00:00&lt;00:00,  1.95 examples/s]"
          }
        },
        "f14a89a5cefb4d8ab3f1f1e912581973": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd07695531324da38889c41d41a59f52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fd559df5929c46a09fa844704dfbe4a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
